import os
from datetime import datetime
from google.cloud import firestore

def montar_prompt(logs, servico):
    mensagens = [log.get("mensagem", "") for log in logs]
    conteudo = "\n".join(mensagens[:20])  # limita a 20 mensagens
    prompt = f"""
Voc√™ √© um assistente t√©cnico. Abaixo est√£o logs do servi√ßo: {servico}

{conteudo}

Com base nesses logs, forne√ßa:
- Um sum√°rio do que est√° acontecendo
- Um poss√≠vel problema identificado
- Uma sugest√£o t√©cnica para corre√ß√£o ou melhoria
"""
    return prompt.strip()

def salvar_sumario(servico, texto_sumario, origem="openai", quantidade_logs=0):
    client_firestore = firestore.Client(project=os.getenv("GCP_PROJECT_ID"))
    doc_ref = client_firestore.collection("logs_sumarios").document()
    doc_ref.set({
        "servico": servico,
        "sumario": texto_sumario,
        "gerado_por": origem,
        "timestamp": datetime.utcnow(),
        "base_de_dados_usada": quantidade_logs,
        "tipo": "analise-logs"
    })
    print(f"‚úÖ Sum√°rio salvo para '{servico}' (ID: {doc_ref.id})")

def gerar_sumario_para_servico(servico, logs):
    from openai import OpenAI

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY n√£o definida no ambiente.")
    
    client = OpenAI(api_key=api_key)

    print(f"\nüß† Gerando sum√°rio para o servi√ßo: {servico} (total: {len(logs)} logs)")
    prompt = montar_prompt(logs, servico)

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0.3,
        messages=[
            {"role": "system", "content": "Voc√™ √© um especialista em logs."},
            {"role": "user", "content": prompt}
        ]
    )

    resposta = response.choices[0].message.content
    print(resposta)
    salvar_sumario(servico, resposta, quantidade_logs=len(logs))
